\documentclass[letterpaper,twocolumn,amsmath,amssymb,pre,aps,10pt]{revtex4-1}
\usepackage{graphicx} % Include figure files
\usepackage{color}
\usepackage{nicefrac} % Include for inline fractions

\usepackage{xargs}                      % Use more than one optional parameter in a new commands
\usepackage[pdftex,dvipsnames]{xcolor}  % Coloured text etc.
\usepackage[colorinlistoftodos,prependcaption,textsize=normalsize]{todonotes}
\usepackage{mdframed}
\usepackage{braket}

% define colors for comments
\definecolor{dark-gray}{gray}{0.10}
\definecolor{light-gray}{gray}{0.70}

\newcommand{\red}[1]{{\bf \color{red} #1}}
\newcommand{\green}[1]{{\bf \color{green} #1}}
\newcommand{\blue}[1]{{\bf \color{blue} #1}}
\newcommand{\cyan}[1]{{\bf \color{cyan} #1}}

\newcommand{\davidsays}[1]{{\color{red} [\green{David:} \emph{#1}]}}
\newcommand{\jpsays}[1]{{\color{red} [\blue{Jordan:} \emph{#1}]}}
\newcommandx{\jpcom}[2][1=inline]{\todo[linecolor=gray,backgroundcolor=light-gray,bordercolor=dark-gray,#1]{\textbf{Jordan says:} #2} }
\begin{document}

\title{Flat histogram method comparison on 2D Ising Model
}

\author{Jordan K. Pommerenck} \author{David Roundy}
\affiliation{Department of Physics, Oregon State University,
  Corvallis, OR 97331}

\begin{abstract}
In this work, we finish writing everything before the abstract~\jpsays{FIX AT END}
\end{abstract}

\maketitle

\section{Introduction}
Flat histogram Monte-Carlo simulation algorithms calculate the thermodynamic
properties of various systems over a range of temperatures.  The first histogram
method used a single canonical Monte Carlo simulation to predict properties for
nearby temperatures~\cite{ferrenberg1988new}. While the method effectively
samples a narrow energy range given limited by a narrow temperature range, it
proves computationally inefficient at sampling large energy ranges.

Due to a canonical Monte Carlo simulation's inefficient sampling of large
energies, a variety of ``flat'' (or ``broad'') histogram
methods~\cite{penna1996broad, penna1998broad, swendsen1999transition,
wang2001determining, wang2001efficient} were developed to explore a wider range
of energies.  In addition to obtaining thermodynamic information for the entire
energy range for a single simulation, these approaches cannot be easily trapped
in a local energy minimum like a canonical simulation.


Wang and Landau introduced one of the most widely used flat-histogram
Monte-Carlo algorithms that accurately determined the density of states (DOS) for
a statistical system~\cite{wang2001determining,wang2001efficient}. For all of
its power, the method unfortunately requires a priori knowledge of several
user-defined parameters. Thus, for any given system under study, the user needs
to determine the ideal parameters in order to apply the method. The Wang-Landau
algorithm is also known to violate detailed balance (although only for brief
time intervals)~\cite{yan2003fast, shell2002generalization}. With the violation
of detailed balance, convergence of the algorithm is not guaranteed.

Because of the uncertainty of convergence for WL, many studies were undertaken
to understand how the modification (or update) factor $\gamma$ impacts the
convergence~\cite{zhou2005understanding,lee2006convergence,
belardinelli2007wang}. The ideal choice of decreasing the modification factor
helps to prevent CPU time from being wasted by continuing to perform
calculations after the error in the density of states is
saturated~\cite{belardinelli2008analysis}. Modification factors that decrease
faster than $1/t$ were found to lead to
non-convergence~\cite{belardinelli2007fast}.  These findings led to the
formation of the $1/t$-WL algorithm.

Liang independently considered whether WL could be treated as a special case of
Stochastic Approximation whose convergence could be mathematically
proven~\cite{liang2006theory, liang2007stochastic}. In 2007, Liang et
al.~\cite{liang2007stochastic} argued that WL can be considered a form of
Stochastic Approximation Monte Carlo (SAMC). Unlike WL, SAMC can guarantee
convergence (if certain conditions are met). Despite the added benefit of
guaranteed convergence, the method still has a system specific user-defined
variable. Such variables often create difficulty when applying Monte-Carlo
methods across arbitrary systems.  The SAD (Stochastic Approximation with
Dynamic $\gamma$) method~\jpsays{outlined by Pommerenck et.al include David and
my paper on SAD square well in citations!} is a special version of the SAMC
algorithm that dynamically chooses the modification factor rather than relying
on system dependent parameters. SAD shares the same convergence properties with
SAMC while replacing un-physical user-defined parameters with the algorithms
dynamic choice.  In this work, we apply the family of weight-based flat
histogram Monte Carlo methods (WL, 1/t-WL, SAMC, SAD) to the 2D Ising model.

\section{Ising Model}
The 2D Ising spin-lattice system is widely used as a testbed when
benchmarking or comparing Monte-Carlo
methods~\cite{ferdinand1969bounded, wang1999transition, trebst2004optimizing}. The 2nd order
phase transition behavior and the ability to directly calculate the
exact solution for finite lattices~\cite{beale1996exact} make the
system sufficiently interesting for such theoretical comparisons. It is
also of important note that direct comparison of the other methods can
be made with WL as its original implementation was done on this
system~\cite{wang2001determining,wang2001efficient}.
We test the convergence of several flat histogram methods
on the periodic 2D square lattice ferromagnetic Ising model with nearest
neighbor interactions~\cite{landau2004new}.
\begin{align}
\mathcal{H} = -\sum_{\braket{i,j}} \sigma_i \sigma_j - h \sum_i s_i
\end{align}
The $N\times N$ spin system can take on values of $\sigma_i = \pm 1$
for up or down spins respectively. In the infinite volume limit ($h =
0$), We can write the Hamiltonian as follows~\cite{onsager1944crystal,
kaufman1949crystal}:
\begin{align}
\mathcal{H} = -\sum_{\braket{i,j}} \sigma_i \sigma_j
\end{align}
where the sum is over all enumerated spin sites. Beale showed that for finite
lattices the Density of States could directly be calculated from the partition
function~\cite{beale1996exact}
\begin{align}
Z = \sum_E g(E) e^{-{\beta E}}
\end{align}
where $g(E)$ is the multiplicity of the system which is identical to
$D(E)$. We can estimate the average deviation from the exact solution
using the relation~\cite{schneider2017convergence, shakirov2018convergence,
barash2017control}:
\begin{align}
\braket{\epsilon(t)}_E = \frac{1}{N_E - 1} \sum_E \left( \frac{S(E,t) - S_{\text{Beale}(E)}}{S_{\text{Beale}(E)}} \right)
\end{align}
As per the implementation by Wang and
Landau~\cite{wang2001determining}, the total number of available energy
states are $N-1$.
\jpsays{Also the necessary condition that the ground state is
$2$ for the 2D Ising model is enforced to guarantee the accuracy of the
density of states at low temperatures. If $2^N$ states is the condition
used for the ferromagnetic ising model, the rescaled factor is
determined primarily by the maximum density of states impacing the
accuracy of the energy levels at or near the ground state.}
%\section{Discrete Spin Systems} In this work, we compare the
%convergence properties of the family of Weight-Based Broad Histogram
%Methods applied to the Q-State Potts model and Ising model. The two
%classical spin systems are ideal testbeds for comparing the convergence
%of Monte-Carlo methods. The Potts and Ising models have 1st and 2nd
%order phase transitions respectively and will both require energy
%binning due to the discrete energy levels of the systems. Convergence
%scaling for the family of Weight-Based Broad Histogram methods can
%easily be explored on the two non-continuous systems.

%\subsection{Potts Model}
%We test the convergence of several Broad Histogram methods
%on the periodic 2D square lattice ($Q=8$) Potts model with nearest
%neighbor interactions~\cite{landau2004new}. The $N\times N$ spin system can
%take on values of $q_i = 1,2,3...Q$ for the Potts spin at site $i$. We
%can write the Hamiltonian as follows:

%\begin{align}
%\mathcal{H} = \sum_{<i,j>} \delta(q_i,q_j)
%\end{align}

%The 2D ten state (Q=10) Potts Model was used as a test system for the Wang
%Landau method during its inception~\cite{wang2001determining,wang2001efficient}.
%Some of the popularity of the model is due to knowledge of exact solutions
%and access to extensive simulation data~\cite{wu1982potts}.
%\jpsays{
%(1) The latent heat of the system which can be obtained by plotting U vs T
%and looking at how much U drops at Tc.
%(2) Looking at the value for the critical temperature Tc.
%Or it is possible that they clarify in a later work~\cite{landau2004new} how
%to extract the correct density of states (Q = 8) in this work.
%\begin{align}
%\sum_E g_N\left( E\right)=Q^N
%\end{align}
%Also the number of ground states (where $E = -2N$) is $Q$. He then re-scales
%the density of states $g_N\left( E\right)$ and writes
%\begin{align}
%\ln \left[ g_N\left(E\right)\right]=\ln \left[ g\left( E\right)\right]
%-\ln \left[ g\left(E=-2N\right)\right]+\ln\left[ Q \right]
%\end{align}
%He calls this the normalized density of states (for his work Q = 10). The
%transition temperature for a 2D lattice $k_B T_C\left(L\right)$ can be directly
%calculated~\cite{landau2004new} and compared with the known value,~\cite{wu1982potts}
%\begin{align}
%k_B T_C = \frac{1}{\ln\left(1+(Q)^{0.5}\right)}
%\end{align}
%Mention: 1st order phase transition nearest neighbor and Hamiltonian
%}
\section{Flat histogram methods}\label{sec:histogram}
Flat histogram methods determine the density of states $D(E)$ over a broad range
of energies by simulating each energy with equivalent accuracy. Flat histogram
Monte Carlo methods propose randomly chosen ``moves'' which change the state of
the system and must satisfy detailed balance.  Each algorithm differs in how it
determines the probability of accepting a move and in what additional statistics
must be collected in order decide on that probability.

We describe four closely related flat histogram methods which each rely on a
weight function $w(E)$ to determine $D(E)$.  For these algorithms, the
probability of accepting a move is given by
\begin{equation}
	\mathcal{P}(E_\text{old} \rightarrow E_\text{new})
	= \min\left[1,\frac{w(E_\text{old})}{w(E_\text{new})}\right]
\end{equation}
which biases the simulation in favor of energies with low weights. The result of
weights $w(E)$ that are proportional to $D(E)$ is an entirely flat histogram. We
can relate the entropy to the weights in the microcanonical ensemble, since the
entropy is defined as $S(E) \equiv k_B\ln(D(E)) \approx \ln w(E)$.

Each approach uses a random walk in energy space to estimate $D(E)$.  At the
core of each of these approaches is to continuously update the weights at each
step of the simulation
\begin{equation}
	\ln{w_{t+1}(E)}=\ln{w_{t}(E)}
	+\gamma_t
\end{equation}
where $t$ is number of the current move, $\gamma(t)$ is a move-dependent update
factor, and $E$ is the current energy.  This update causes the random walk to
avoid energies that have been frequently sampled, leading to a rapid exploration
of energy space. The four methods differ primarily in how they schedule the
decreasing of $\gamma_t$.

The Wang-Landau algorithm~\cite{wang2001efficient,wang2001determining,
landau2014guide} explores energy space by initially setting $\gamma=1$, and then
decreases $\gamma$ in discrete stages. An energy range of interest must be
specified~\cite{wang2001efficient, schulz2003avoiding, yan2003fast},
which can require multiple simulations if unknown.

The number (``counts'') of moves ending at each energy are stored in a
histogram.  For a sufficiently flat energy histogram (specified by the user to
typically be 0.8), $\gamma$ is decreased by a specified factor of $\frac12$ and
the histogram is reset to zero. The entire process is repeated until $\gamma$
reaches a desired cutoff.

Zhou et. al also showed that the WL algorithm never converges
exponentially~\cite{zhou2008optimal} and succesfully bounded the statistical
error between $t^{-\frac12}$ and $1/t$~\cite{zhou2008optimal}. He also suggests
that a modification factor of $1/t$ is optimal for WL.

The $1/t$-WL method is a refinement of the original implementation that
addresses the error saturation of WL. Belardinelli and Pereyra
implemented a schedule~\cite{belardinelli2007fast} that enforced that
if $\gamma < \nicefrac{1}{t}$ then the update factor is set to
$\nicefrac{1}{t}$ and the histogram is no longer tracked. Using this
metric, the error saturation is avoided since the correct density of
states is approached asymptotically as
$t^{-\frac12}$~\cite{belardinelli2008analysis}.

\jpsays{I am here!}

Schneider $\text{et. al}$ outline minor refinements to the $1/t$-WL algorithm
including $\nicefrac{N_S}{t}$ scaling and switching from standard WL to
$1/t$-WL when the update factor $\gamma <
\nicefrac{N_S}{t}$~\cite{schneider2017convergence}. As per the original
$1/t$ implementation~\cite{belardinelli2007fast}, the update factor is
decreased once all $N_S$ energy states are visited at least once (i.e.
$H(E) \neq 0$) effectively avoiding the concept of `flatness'.  In this
work, we refer to this refined algorithm as $1/t$-WL, with the update
factor asymptoting to $\nicefrac{N_S}{t}$.

\subsection{SAMC}
The Stochastic Approximation Monte Carlo (SAMC) algorithm has a simple
schedule by which the update factor $\gamma$ is continuously
decreased~\cite{liang2007stochastic, werlich2015stochastic,
schneider2017convergence}.  The update factor is defined in the
original implementation~\cite{liang2007stochastic} in terms of an
arbitrary tunable parameter $t_0$,
\begin{align}
\gamma_{t}^{\text{SA}} =\frac{t_0}{\max(t_0,t)}
\end{align}
where as above $t$ is the number of moves that have been attempted.
SAMC offers extreme simplicity and proven convergence.
Provided the update factor satisfies
\begin{align}
\sum_{t=1}^\infty \gamma_{t} = \infty \quad\textrm{and}\quad
\sum_{t=1}^\infty \gamma_{t}^\zeta < \infty
\end{align}
where $\zeta \in \{1,2\}$, Liang has shown that the weights are proven
to converge to the true density of states~\cite{liang2006theory,
liang2007stochastic}.  Unlike WL methods, the energy range need not be
known \emph{a priori.}  The convergenc time depends only on the choice of
parameter $t_0$.  Liang \emph{et al.} give a rule of thumb in
which $t_0$ is chosen in the range from $2N_S$ to $100N_S$ where $N_S$
is the number of energy bins~\cite{liang2007stochastic}.  Schneider
\emph{et al.} found that for the Ising model this heuristic is helpful
for small spin systems, but that larger systems require an even higher
$t_0$ value~\cite{schneider2017convergence}.

\subsection{SAD Algorithm}\label{sec:sad}
In our previous work we discuss this in detail so here we only highlight...
Stochastic Approximation w/ Dynamic $\gamma$ here.

\section{Results}
\begin{figure}
\includegraphics[width=\columnwidth]{figs/ising/gamma-n32.pdf}
  \caption{
  gamma plot}
\end{figure}

\begin{figure}
\includegraphics[width=\columnwidth]{figs/ising/gamma-n128.pdf}
  \caption{
  gamma plot}
\end{figure}

\subsection{The 32 $\times$ 32 Ising model}
Something small...
\begin{figure}
\includegraphics[width=\columnwidth]{figs/ising/N32-entropy-error-default.pdf}
  \caption{
  The average entropy error for each MC method for $N=32 \times 32$,
               $\delta_0 = 0.05\sigma$, and $T_{\min} = 1$
               as a function of number of iterations run.  The error is
               averaged over 8 independent simulations, and the best
               and worst simulations for each method are shown as a
               semi-transparent shaded area.}\label{fig:n32}
\end{figure}
\begin{figure}
\includegraphics[width=\columnwidth]{figs/ising/N128-entropy-error-default.pdf}
  \caption{
  The average entropy error for each MC method for $N=128 \times 128$,
               $\delta_0 = 0.05\sigma$, and $T_{\min} = 1$
               as a function of number of iterations run.  The error is
               averaged over 8 independent simulations, and the best
               and worst simulations for each method are shown as a
               semi-transparent shaded ar.}\label{fig:n128}
\end{figure}

\subsection{128 $\times$ 128 Ising system}
Something big (WL uses 256 by 256 in their paper but only one simulation and
no comparison while more recent comparison type papers use 128 by 128 as max)...

\section{Conclusion}

\section{Acknowledgements}

\bibliography{ising} % Produces the bibliography via BibTeX.

\end{document}
