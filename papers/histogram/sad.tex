\documentclass[letterpaper,twocolumn,amsmath,amssymb,pre,aps,10pt]{revtex4-1}
\usepackage{graphicx} % Include figure files
\usepackage{color}
\usepackage{nicefrac} % Include for inline fractions

\newcommand{\red}[1]{{\bf \color{red} #1}}
\newcommand{\green}[1]{{\bf \color{green} #1}}
\newcommand{\blue}[1]{{\bf \color{blue} #1}}
\newcommand{\cyan}[1]{{\bf \color{cyan} #1}}

\newcommand{\davidsays}[1]{{\color{red} [\green{David:} \emph{#1}]}}
\newcommand{\jpsays}[1]{{\color{red} [\blue{Jordan:} \emph{#1}]}}
\newcommand{\tssays}[1]{{\color{red} [\cyan{Tanner:} \emph{#1}]}}

\begin{document}
\title{Stochastic Approximation Monte Carlo with a Dynamic Update
Factor (SAD)
}

\author{Jordan K. Pommerenck} \author{Tanner T. Simpson}
\author{Michael A. Perlin} \author{David Roundy}
\affiliation{Department of Physics, Oregon State University,
  Corvallis, OR 97331}

\begin{abstract}
  We present a novel Monte-Carlo algorithm based on Stochastic
  Approximation Monte Carlo (SAMC) algorithm for directly calculating
  the density of states. The proposed method is Stochastic
  Approximation with a dynamic update factor (SAD-$\gamma$ or SAD)
  dynamically adjusts the update factor $\gamma$ during the course of
  the simulation. We test this MC method on the square-well fluid and
  compare the convergence time and entropy error for a variety of weight-based
  and transition matrix Monte-Carlo methods. SAD rapidly converges to the
  correct density of states without the need for the user to specify an
  arbitrary tunable parameter $t_0$ as in the case of SAMC.
\end{abstract}

\maketitle

\section{Introduction}
Over the past several decades a number of flat histogram Monte-Carlo
simulation algorithms have been developed which calculate the
thermodynamic properties of various systems for all temperatures.  The
development began with the original histogram method, which used a
single canonical Monte Carlo simulation to predict properties for
nearby temperatures~\cite{ferrenberg1988new}.  For large simulations
this approach is limited to a narrow temperature range because a single
canonical simulation explores only a small range of energies.  This led
to a variety of ``broad'' (or ``flat'') histogram
methods~\cite{penna1996broad, penna1998broad, swendsen1999transition,
wang2001determining, wang2001efficient, trebst2004optimizing}, which
attempt to explore a wide range of energies.  These methods also
benefit in that they are unlikely to be trapped in a low enetropy state.

Wang and Landau introduced an algorithm that uses an update factor and
a statistical histogram to compute the density of states of a given
system~\cite{wang2001determining, wang2001efficient}.  While the method
is incredibly powerful, it has several user-defined
parameters~\cite{landau2004new}.  This can make its application to a
variety of systems something of an art-form since the user needs to
determine the ideal parameters for the particular system being studied.
Also, detailed balance is violated (although only for short periods of
time), ensuring that convergence is not guaranteed.  This raises
several questions such as when the method does converge, what rate will
the method converge to the correct density of states. Also, how can the
user appropriately decide what parameters to choose so that the
algorithm solves the problem in the most ideal way.

%Transition Matrix Monte Carlo~\cite{wang1999transition,
%swendsen1999transition, fitzgerald2000monte} became an attractive
%complimentary simulation algorithm to Wang-Landau, in that, if detailed
%balance is ensured, the system is guaranteed to converge.  Unfortunately,
%the algorithm can be considerably more difficult to implement when
%compared to Wang-Landau: in particular, due to the infinite temperature
%transition matrix~\cite{wang2002transition}.  Also, the time necessary
%for the density of states to converge could be considerable
%due to the algorithm spending too much time exploring low energy states.
%Unlike WL, TMMC does not require a prior knowledge of the energy range of
%the system.
%
%Shell et al.~\cite{shell2003improved, shell2004flat} originially
%implemented Wang-Landau Transition Matrix Monte Carlo (WL-TMMC) in an
%effort to quickly explore the energies of a given system using WL then
%switch over to TMMC to guarantee convergence. Considerable effort has
%been spent trying to determine the flatness criteria and cutoff for the
%WL portion, but there remains no rigorous systematic way to determine
%these parameters~\cite{rane2013monte}.  The algorithm is first run for
%several trial simulations and/or `experience' is used to determine the
%best parameters for a users particular system of
%study~\cite{siderius2013use}.
Around the same time, the convergence rate for WL was being
explored~\cite{zhou2005understanding,lee2006convergence,
belardinelli2007wang}. It was found that utilizing modification factors
that decrease faster than $1/t^2$ leads to
nonconvergence~\cite{belardinelli2007fast}.  This leads to the so-called
$1/t$-WL algorithm which ensures that excess CPU time is not wasted by
continuing to perform calculations once the error in the density of
states becomes saturated~\cite{belardinelli2008analysis}. An effort to
reduce the number of user defined parameters of WL and formulate a
theory for why the method converges despite detailed balance being
violated although infrequently was also being undertaken.

Liang, Liu, and Carrol began to consider whether WL could be considered
a special case of Stochastic Approximation whose convergence could be
mathematically proven~\cite{liang2006theory, liang2007stochastic}. In
2007, Liang et al.~\cite{liang2007stochastic} argued that WL can be
considered a form of Stochastic Approximation Monte Carlo (SAMC). While
SAMC can guarantee convergence, the method still has a system specific
user-defined variable which makes applying this algorithm to arbitrary
systems difficult.

In this work, we have developed a novel algorithm based on SAMC that
does not require user-defined inputs and therefore should be easily
applicable to a given system.  We call this method SAD (Dynamic
Stochastic Approximation), and will discuss it in detail in the methods
section. We compare it along with several flat histogram methods
which include WL, 1/t-WL, and SAMC.
%which include TMMC, WL, WL-TMMC, and SAMC.

We consider the square-well fluid i.e. a system of particles whose
interactions are governed by a square-well
potential~\cite{singh2003surface, barker2004perturbationSW}.  The
square-well potential is an ideal test-bed as it is the simplest model
that ensures both attractive and repulsive forces are experienced by
interacting particles~\cite{barker1967-SW-perturbation, vega1992phase}.
The potential $U(\textbf{r})$ for such a system is given by
\begin{equation}
 U(\textbf{r})=\begin{cases} \infty &
 \lvert\textbf{r}\rvert< \sigma\\-\epsilon &
 \sigma<\lvert\textbf{r}\rvert<\lambda\sigma\\0 &
 \lvert\textbf{r}\rvert > \lambda\sigma\end{cases}
\end{equation}
where $\sigma$ is the hard-sphere diameter of the particle, $\lambda$ is the
reduced range of the potential well, and $\epsilon$ is its depth.

The organization of this paper is as follows: In Section~\ref{sec:histogram}, we
describe in detail flat-histogram methods.  Section~\ref{sec:weight} outlines
weight-based histogram methods used in this work.
%Section~\ref{sec:transition}
%details the workings of the transition-matrix methods studied in this work.

Section~\ref{sec:sad} introduces the dynamic stochastic approximation method.
In Section~\ref{sec:results}, we discuss the performance of the various methods
applied to the model system.

In this work, We compare a variety of flat histogram
methods.  We outline the general workings of each algorithm that we
developed in detail while summarizing algorithms that were developed in other
works.  The following methods are introduced and applied to the
square-well fluid: Wang-Landau (WL), 1/t-Wang-Landau (1/t-WL), Stochastic
Approximation Monte-Carlo (SAMC), and Dynamic Stochastic Approximation (SAD).

%Transition Matrix Monte-Carlo (TMMC), Wang-Landau
%(WL), Wang-Landau Transition Matrix Monte-Carlo (WL-TMMC), Stochastic
%Approximation Monte-Carlo (SAMC), and Dynamic Stochastic Approximation
%(SAD).

\section{Flat histogram methods}\label{sec:histogram}

The goal of flat histogram methods (also called \emph{broad histogram}
or \emph{multicanonical} methods) is to simulate each energy with
similar accuracy, so as to accurately determine the density of states
over a broad range of energies.  Once the density of states is known,
a number of thermodynamic quantities---such as heat capacity or
internal energy---can be easily computed for any temperature.
Properties that require more information---such as a spatial
correlation function or a response function---can still be computed
for any temperature, provided statistics are collected for each
individual energy, which can then be reweighted for any temperature.

Each flat histogram Monte Carlo method uses a given set of ``moves''
which change a system and should satisfy detailed balance.  Each
algorithm differs in how it determines the probability of accepting a
move, and in what additional statistics (if any) must be collected in
order decide on that probability.  The methods we will compare fall in
two categories:  weight-based methods, which only require a set of
weights $w(E)$ be collected, and transition-matrix methods that
require that statistics be collected for any transitions between pairs
of energies.

Both weight-based and transition matrix methods calculate
the density of states $D(E)$ for discrete energy
levels~\cite{haber2018performance}. For this reason, energy binning
becomes an important consideration for complex continous systems.
Energy bins are typically of uniform size for the entire energy
continuum~\cite{fasnacht2004adaptive}. Some methods such as
AdaWL~\cite{koh2013dynamically}
employ a tunable mechanism for controlling the binning for low entropic
states in order to ensure the exploration of all energies.  The method
introduced in this paper is designed to scale appropriately as bin size
is changed, but we do not test this scaling, as we use a system with
discrete energy levels.

\section{Weight-based methods}\label{sec:weight}

We will begin by introducing two related weight-based methods which
rely on a weight function $w(E)$, noting that the method proposed in
this paper (discussed in Section~\ref{sec:sad}) also falls in this
category.  In these algorithms, the probability of accepting a move is
given by
\begin{equation}
	\mathcal{P}(E_\text{old} \rightarrow E_\text{new})
	= \min\left[1,\frac{w(E_\text{old})}{w(E_\text{new})}\right]
\end{equation}
the probability biases the simulation in favor of energies with low weights.
A set of weights that are proportional to the density of states of the
system $D(E)$ will result in an entirely flat histogram.  Thus
flat histogram is a criteria for convergence for these methods.  To avoid
overflow error , since the weights may vary over more than a
few hundred orders of magnitude, the natural logarithm of the weights are used
in this work.  Since $D(E) = S(E)$, the logarithm of the weights
can be thought of as an approximation of the entropy.

Each weighted density approach uses a random walk in energy space to
estimate the density of states.  The core of these approaches
is to continuously update the weights at each step of the simulation
\begin{equation}
	\ln{w_{t+1}(E)}=\ln{w_{t}(E)}
	+\gamma
\end{equation}
where $t$ is number of the current move, and $\gamma$ is an update
factor.  This update causes the random walk to avoid energies that
have been frequently sampled, leading to a rapid exploration of energy
space.  This approach, however, violates detailed balance, due to the
acceptance probabilities changing with each move.  The severity of
this violation decreased as we decrease $\gamma$.  The various
weight-based methods discussed here differ in how the decreasing of $\gamma$
is scheduled.

\subsection{Wang-Landau}

Wang-Landau's approach~\cite{wang2001efficient,wang2001determining,
  landau2014guide} begins with $\gamma=1$, and then decreases $\gamma$
in discrete stages.  We track the number of steps at each energy during
each stage in a histogram.  When that histogram is sufficiently flat,
$\gamma$ is decreased by a specified factor, which is usually
$\frac12$.  The flatness is defined by the ratio between the minimum
value of the histogram and its average value.  When this flatness
reaches a specified threshold (typically 0.8), the $\gamma$ value is
decreased.  This approach requires that the energy range of interest
be known in advance, and difficulties can occur with this flatness
criteria due to the fact that some energies in this energy range might
never be sampled~\cite{haber2014transition}.  The entire process is
repeated until $\gamma$ reaches a desired cutoff.

The Wang-Landau approach thus has three parameters that need be
specified: the factor by which to decrease $\gamma$ when flatness is
acheived, the flatness criterion, and the cutoff that determines when
the computation is complete.  In addition, an energy range (or more
specifically, a set of energies) must be supplied, so that the
flatness criterion can be defined.

While this approach
is very efficient and has been widely used, it suffers a few
shortcomings.  Firstly, the set of energies must be specified
~\cite{wang2001efficient, schulz2003avoiding, yan2003fast}, which may
require multiple simulations. Secondly, while Wang-Landau converges quickly,
it does not in general converge to the true density of states
~\cite{belardinelli2008analysis, zhou2008optimal}.  It can and does decrease
$\gamma$ so quickly that it will never (for any cutoff value) decrease the
error in the density of states beyond a given value.

\subsection{$1/t$ Wang-Landau}
The Wang-Landau algorithm's error saturation can be corrected by
modifying the update factor such that it does not decrease too quickly.
Belardinelli and Pereyra raised the question as to whether the update
factor should be decrease by $\nicefrac12$ or some other factor for
each update~\cite{belardinelli2007fast}. They implemented a schedule
that enforced if the update factor $\gamma$ is less than
$\nicefrac{N_S}{t}$ then the update factor is set to
$\nicefrac{N_S}{t}$ and the histogram is no longer tracked. Employing
this scheduler, they found that the error saturation is avoided since
the correct density of states is approached asymptotically as
$t^{-\frac12}$~\cite{belardinelli2008analysis}. Zhou et. al further
confirmed that the WL algorithm never converges exponentially and
succesfully bounded the statistical error between
$t^{-\frac12}$ and $\nicefrac{1}{t}$~\cite{zhou2008optimal}.

Schneider et. al outlines minor refinements to the $1/t$ WL algorithm
including $\nicefrac{N_E}{t}$ scaling and switching from standard WL to
$1/t$ WL when the update factor $\gamma <
\nicefrac{N_E}{t}$~\cite{schneider2017convergence}. As per the original
$1/t$ implementation~\cite{belardinelli2007fast}, all energy states $N_E$
are required to be visited at least once $H(E) \neq 0$ effectively
avoiding the concept of `flatness'.


\subsection{SAMC}
The Stochastic Approximation Monte Carlo (SAMC) algorithm addresses
the lack of convergence of Wang-Landau's approach with a simple
schedule by which the update factor $\gamma$ is continuously
decreased~\cite{liang2007stochastic, werlich2015stochastic,
  schneider2017convergence}.  The update factor is defined in the
original implementation~\cite{liang2007stochastic} in terms of an
arbitrary tunable parameter $t_0$.
\begin{align}
\gamma_{t}^{\text{SA}} =\frac{t_0}{\max(t_0,t)}
\end{align}
where as above $t$ is the number of moves that have been attempted.
The major advantage that SAMC offers is its proven convergence.
Provided the update factor satisfies
\begin{align}
\sum_{t=1}^\infty \gamma_{t} = \infty \quad\textrm{and}\quad
\sum_{t=1}^\infty \gamma_{t}^\zeta < \infty
\end{align}
where $\zeta \in \{1,2\}$, Liang has shown that the weights are proven
to converge to the true density of states~\cite{liang2006theory,
  liang2007stochastic}.  In addition, the energy range need not be
known a priori.  The time to converge depends only on the choice of
parameters $t_0$.  Unfortunately, there is no
prescription for finding an acceptable value for $t_0$, and
while the algorithm formally converges, for a poor choice of $t_0$
that convergence can be far too slow to be practical.
Liang et al. give a rule of thumb in which $t_0$
is chosen in the range from $2N_S$ to $100N_S$ where $N_S$ is the number
of energy bins~\cite{liang2007stochastic}.  Schneider et al. found
that for the
Ising model this heuristic is helpful for small spin
systems, but that larger systems require an even higher $t_0$
value~\cite{schneider2017convergence}.  Also, we find that for the square-well
fluid $t_0$ in some cases needs to be two orders of magnitude higher
than the rule of thumb of $100N_S$.

Werlich \emph{et al.} proposed scaling the SAMC $\gamma_t$ by a factor
$\gamma_0$.  While this may result in an improved rate of convergence,
it adds yet another parameter that must be empirically determined, and
we have not explored this degree of freedom.

\subsection{SAMC Convergence}\label{sec:samc-convergence}
The difficulty in using the SAMC method lies in identifying an appropriate
value for $t_0$.  A value that is either too high or too low will result
in slow convergence to the true entropy.  It is instructive to consider
separately values of $t_0$ that are too low or too high.

We can place a rigorous \emph{lower} bound $t_{\min}$ on the number of
moves required to find the true energy by considering the total change
that needs to be made to the entropy.
\begin{align}
  \Delta S_{\text{tot}} \equiv \sum_E S(E) - S_{\min}
\end{align}
The minimum number of moves that could converge the entropy is
the number of moves that will enable the above total entropy change,
which we can approximate using an integral:
\begin{align}
   \Delta S_{\text{tot}} &= \sum_{t=0}^{t_{\min}} \gamma_t \\
  % &= \int_0^{t_{\min}} \gamma(t)dt \\
  &= t_0 + \int_{t_0}^{t_{\min}} \frac{t_0}{t}dt
  \\
  &= t_0\left(1 + \ln\left(\frac{t_{\min}}{t_0}\right)\right)
\end{align}
Solving for ${t_{\min}}$ we find that
\begin{align}
  {t_{\min}} &= t_0 e^{\frac{\Delta S_{\text{tot}}}{t_0} - 1}
\end{align}
which means that the minimum time to convergence grows exponentially
as $t_0$ is made smaller.  You \emph{seriously} don't want to underestimate
$t_0$!

One might reasonably choose to err on the high side when selecting a $t_0$.
The rate of convergence is harder to estimate when $t_0$ is large, but
in general $\gamma_t$ itself forms a lower bound on the accuracy with which
the entropy may be known, with an unknown prefactor which is roughly
the coherence time of the Monte Carlo simulation.  Since $\gamma_t$ is
given by $t_0/t$, the time to converge to a given accuracy is increased
in proportion to the ratio by which we overestimate $t_0$.  Thus, while
it is exponentially painful to underestimate $t_0$, overestimating by
several orders of magnitude is also not acceptable.  We should note
that these extreme limiting cases do not preclude the possibility that there
is a wide range of $t_0$ values that lead to an acceptable convergence
rate.

%\section{Transition-matrix methods}\label{sec:transition}
%
%\subsection{TMMC Algorithm}
%The previously described weight-based flat-histogram methods utilizes a so-called
%``visited states'' approach to calculate  thermodynamic
%properties~\cite{errington2003direct}. The algorithm is fundamentally
%based on the number of times a given state is visited while the
%system is being sampled. The Transition Matrix Monte Carlo (TMMC) method operates
%differently than the visited states approach~\cite{fitzgerald2000monte}.
%The method uses attempted transitions between states to obtain an estimate of
%the probability that a given transition will be proposed.  The density
%of states is computed from the resulting transition matrix.  An advantage
%of collecting the transition matrix is that this matrix may be collected
%while another method is employed to compute acceptance probabilities, as
%in Wang-Landau TMMC, discussed below.
%
%The TMMC algorithm records the transition data in a \emph{collection matrix},
%i.e. the unnormalized transition histogram matrix, which stores the number
%of times a transition between two energy states has been proposed.
%\begin{align}
%  C(E_{\text{old}} \rightarrow E_{\text{new}},t+1)
%     = C(E_{\text{old}} \rightarrow E_{\text{new}},t) + 1
%\end{align}
%The transition matrix is computed from the collection matrix via
%\begin{align}
%  T(E_{\text{old}} \rightarrow E_{\text{new}})
%   = \frac{C(E_{\text{old}} \rightarrow E_{\text{new}})}{
%     \sum_E C(E_{\text{old}} \rightarrow E)
%  }
%\end{align}
%The acceptance probability is defined in terms of this biasing function:
%\begin{align}
%  \mathcal{P}(E_{\text{old}} \rightarrow E_{\text{new}}) =
%  \max\left(1,\frac{T(E_{\text{old}} \rightarrow E_{\text{new}})}{
%       T(E_{\text{new}} \rightarrow E_{\text{old}})}\right)
%\end{align}
%where we note that the transition matrix is updated to reflect the
%transition under consideration \emph{prior} to computing the acceptance
%probability.  The TMMC method suffers from poor convergence primarily
%because it is sensitive to poor statistics in less probable energy
%transitions.  Like the weight-based methods above, the TMMC method violates
%detailed balance, with the level of violation decreasing as the simulation
%progresses and a difference of 1 in the collection matrix has a smaller
%impact on the acceptance probabilities.
%
%\subsection{WL-TMMC Algorithm}
%Wang-Landau Transition Matrix Monte-Carlo (WL-TMMC) method as proposed
%by Shell and coworkers~\cite{shell2003improved,shell2004flat} takes
%advantage of the WL methods ease of implementation, while making use of
%a transition matrix to address WL weaknesses, such as its limited
%statistical accuracy convergence.
%
%\paragraph{Initializing Wang-Landau:}
%We set the energy range along which the method may sample as
%$E(T_{\min}) <E< E(T=\infty)$. Conventional Wang-Landau prescribes
%updating the WL factor $\gamma$ by starting at 1.0 and reducing by
%$\frac12$ until the simulation is cutoff typically around $10^{-10}$.
%While variants of this approach appear in the literature, Rane et. al.
%published an implemenation of WL-TMMC~\cite{rane2013monte} that
%suggested using a WL factor between 1.0 and $10^{-2}$ with a cutoff
%$<10^{-5}$, We implement WL-TMMC by setting the WL factor to be 1.0 and
%the cutoff to be either $10^{-4}$ or $10^{-10}$.
%
%A single sweep ``roundtrip'' is defined as each macrostate being
%sampled a number of times in this case 100,000 times. Wang-Landau sets
%a flatness criteria~\cite{wang2001determining, wang2001efficient,
%hatch2015computational, mahynski2017predicting} for the accumulated
%histogram usually to be 0.8.  In the original implementation, it was
%found to be sufficient that each macrostate is visited at least once
%(each histogram bin has one entry)~\cite{shell2003improved}; however,
%for other systems this is rarely sufficient~\cite{bhar2009computer}.
%The goal of this WL initialization is to prefill the transition matrix
%for the next portion of the simulation.
%
%\paragraph{Initializing TMMC:} Prefilling the transition matrix is
%necessary because if numerous zeros existed in the collection matrix,
%the infinite temperature transition matrix would be ill-defined.
%Sampling over large ranges of density of states would therefore take an
%unacceptable length of time to complete~\cite{shell2003improved,
%shen2014elucidating}.  The TMMC portion of the algorithm is run only
%after WL has reached the specified cutoff. An important note is that
%the acceptatnce probability for TMMC is only used to control actual
%transitions not update the collection matrices.

\section{SAD Algorithm}\label{sec:sad}
The Stochastic Approximation with Dynamic update factor (SAD) method
is a variant of the SAMC
Algorithm that attempts to dynamically choose the modification factor
rather than relying on system dependent parameters such as $t_0$ or
$\gamma_0$.  There is an immediate advantage of such an algorithm where
parameters are chosen independent of system size or type. Each
Flat-Histogram method has unique advantages and disadvantages.
Wang-Landau requires an energy range for initialization.  SAMC removes
this energy range requirement but requires simulating every possible
energy. Our proposed method SAD requires the user to input
$T_\text{min}$ which is an immediate disadvantage of the method;
however, this allows the user to define an energy simulation
range between $T_\text{min}$ and $\infty$. Setting a physical parameter
such as a minimum temperature $T_\text{min}$ is intuitive vs. a user
needing to know a prior either an energy range or some unphysical
parameter $t_0$.

\begin{figure}
  \includegraphics[width=\columnwidth]{figs/N50-lndos-comparison}
  \caption{The entropy of a square well fluid with 50 atoms and filling fraction
        0.3 as the green line.  The green hatched area reflects the
        minimum entropy change needed to converge to the true value.
        The light blue area is the quadratic approximation
        for the change in entropy.  The vertical dotted lines represent
        the energy corresponding to $T=1/3$ and $T=\infty$.}
  \label{fig:entropy-cartoon}
\end{figure}

While for SAMC the update factor is defined in the original
implementation, for SAD the update factor $\gamma_{t}^{\text{SAD}}$ is
thought of as $\nicefrac{\text{d}S}{\text{d}t}$. This tells us that
the SAMC parameter
$t_0$ should have dimensions of entropy.
We begin with an estimate of the average value of the entropy (relative
to the lowest entropy at $T_{\min}$).  If we assume a quadratic
dependence on energy (see Fig.~\ref{fig:entropy-cartoon}), this is given by
\begin{align}
\langle S\rangle \approx \frac13 \frac{E({T=\infty}) - E(T_{\min})}{T_{\min}}
\end{align}
We approximate this energy difference by
$E_H -E_L$ where $E_H$ and $E_L$ are defined below.
The entropy numerator of the update factor
in general should scale with the total number of interesting
energy states $N_S$, since updates to the weights are distributed between
that many energy states.  The product $N_S\langle S\rangle$ is the
total change of entropy required (starting from constant weights) to find
the true entropy, and puts a lower bound on the convergence time.
After \emph{long} times, when
all the energies have been long ago found,
we wish for a lower $t_0$ in order to more rapidly refine the remaining
error in entropy.  We enable this
by tracking the last time we encountered a new energy $t_L$, and
gradually transition to lower $t_0$ (but still asymptotically scaling
as $\gamma_t \propto 1/t$ to ensure eventual convergence).  Finally,
we wish for an update factor that is \emph{never} greater than 1, because
a very large update factor could introduce errors in entropy that may take
many iterations to remove.  The SAD
expression for $\gamma_t$ which incorporates these ideas is:
\begin{align}
  \gamma_{t}^{\text{SAD}} =
     \frac{
       \frac{E_{H}-E_{L}}{T_{\text{min}}} + \frac{t}{t_L}
     }{
       \frac{E_{H}-E_{L}}{T_{\text{min}}} + \frac{t}{N_S}\frac{t}{t_L}
     }
\end{align}
This factor asymptotically has the same $1/t$ behavior as the original
SAMC algorithm;
however now every time a new energy is found to be important
during the course of
the simulation, the update factor will experience a jump. This behavior
allows SAD to dynamically prevent the update factor from decreasing too
rapidly.

\begin{figure}
  \includegraphics[width=\columnwidth]{figs/gamma-n256}
  \caption{The update factor $\gamma_t$ for $N=256$ versus iteration for
    four different methods: WL, $1/t$-WL, SAMC, and SAD}
    \label{fig:gamma-vs-t}
\end{figure}
Figure~\ref{fig:gamma-vs-t} compares $\gamma_t$ for the related methods
SAD, WL, $1/t$-WL, and SAMC.  For SAMC, $\gamma_t$ remains constant
before dropping as $1/t$.  WL $\gamma_t$ remains at 1 for many iterations,
and then decreases very rapidly, with $1/t$-WL behaving similarly before
transitioning to a $1/t$ behavior.
The update factor for SAD fluctuates
dynamically around a value less than 1 for early MC moves, and then
decreases as approximately $1/t$ while continuing to fluctuate as 
new energies are found to be important.  At late times, the SAD $\gamma_t$
decreases as approximately $1/t^2$ until asymptoting to $N_S/t$, which
is the same as $1/t$-WL.

Since SAD does not explore \emph{all} energy states it needs determine
what energy range corresponds to the temperature range of interest,
defined by $T_{\min}<T<\infty$.
The
simulation is responsible for determining and updating this energy
range.
Given the true entropy $S(E)$, we can define the interesting energy
range as
%\begin{align}
  $E(T_{\min}) <E< E(T=\infty)$
%\end{align}
where $E(T)$ is the energy that maximizes $S-E/T$.  In the course of the
simulation this precise energy is challenging to evaluate accurately.
In order to ensure that we sample this entire energy range adequately,
we define two energy limits:  a high energy $E_H$ and a low
energy $E_L$, which define the range over which the energy histogram
is made flat. At move $t$, $E_H$ and $E_L$ are the greatest and lowest
energy that has prior to that move
had the highest histogram value (i.e. been visited the most times) in
the course of the simulation.
This definition results in a ``ratcheting'' effect, in which $E_H$
may only increase, while $E_L$ may only decrease over the course of the
simulation, which results in a conservative estimate of the range of
energies that need be sampled.

During the simulation when considering a move outside of the energy
range $E_L \le E \le E_H$, Boltzmann weights are used.  If $E\ge E_H$,
the weight is taken to be
\begin{align}\label{eq:highw}
  w(E>E_H) &= w(E_H),
\end{align}
which corresponds to an infinite temperature.
This choice ensures that
if the maximum in entropy is at an energy $E_{\max}>E_H$, then the energy
$E_{\max}$
will eventually have the highest number of counts and the ratcheting will
result in $E_H\ge E_{\max}$ .
At lower energies, Boltzmann weights corresponding to the minimum temperature
are used:
\begin{align}\label{eq:loww}
  w(E<E_L) &= w(E_L)e^{-\frac{E_L-E}{T_{\min}}}.
\end{align}
This choice has the result that if the energy $E_{\min}$ at which the free
energy at $T_{\min}$ is minimized is less than $E_L$, the lower energy
limit will ratchet down to include $E_{\min}$.
Each time we change the value of $E_H$ or $E_L$, the weights within the
new portion of the interesting energy range are set to the expressions
in Equations~\ref{eq:highw} and~\ref{eq:loww}.

%\begin{figure}
  %\includegraphics[width=\columnwidth]{figs/gamma-n500}
  %\caption{The update factor $\gamma_t$ for $N=500$ versus iteration for three
    %different methods: WL, SAMC, and SAD.
    %method.}\label{fig:gamma-vs-t}
%\end{figure}
\begin{figure}
  \includegraphics[width=\columnwidth]{figs/gamma-n50}
  \caption{The update factor $\gamma_t$ for $N=50$ versus iteration for three
    different methods: WL, SAMC, and SAD.}
\end{figure}

\paragraph{Energy binning with SAD}

A significant advantage of SAD over other flat histogram methods is
that energy binning is solved dynamically. SAD should perform
independently for a reasonable range of binning because $\gamma \propto
\nicefrac{N_S}{t}$.  As the number of energy states found $N_S$
increases (fine binning), the time spent $t$ in each bin will decrease.
This argument explains why SAD should perform well for complex systems
in terms of binning. SAMC has a prefactor $\gamma_0$ to aid in a
similar way but this adds yet another parameter for the user to choose.

\paragraph{Scaling, step size, and SAD}
Methods such as WL can fail to converge for complex systems in part
because the same random MC moves are performed for the entire energy
range.  The main problem lies in trying to determine how to optimize
the step size such that the time to explore all energies is reasonable.
Small step sizes lead to improved sampling at the expense of slow
convergence. Koh et al. proposed multiplying $\gamma$ by an energy
dependent factor in order to improve the converge of WL in regards to
convergence and scaling~\cite{koh2013dynamically}.  Because the update
factor for SAD has an energy dependent factor already present (and
dynamically adjusted), we expect that SAD will perform consitently
scaling free for a reasonable choice of step size.  SAD should perform
extremely well compared with other flat histogram methods when applied
to complex continuous systems such as polymers/proteins and spin models.

\subsection{Convergence}
Because SAD scales as $1/t$ for large $t$, it satisfies the SAMC
convergence criteria.  However, we also want to ensure that SAD avoids
the exponentially poor convergence time that SAMC suffers when $t_0$ is
small as discussed in Section~\ref{sec:samc-convergence}.
To place a lower bound on the convergence of SAD, we will again
approximate the total entropy change using an integral.  To sidestep
the dynamical nature of SAD, we ensure that \emph{after discovering the
last important energy} at time $t_L$ the entropy change
$\Delta S_{\text{tot}}$ can be made in a reasonable number of iterations.
Thus we integrate the update factor from $t_L$ to some minimum time
$t_{\min}$ necessary for convergence.  Technically this is not a lower
bound as in the case of SAMC because the algorithm will already have a
reasonable approximation for the entropy.
\begin{align}
\Delta S_{\text{tot}} &= \int_{t_L}^{t_{\min}}
     \frac{
       3\langle S\rangle + \frac{t}{t_L}
     }{
       3\langle S\rangle + \frac{t}{N_S}\frac{t}{t_L}
     } dt \\
&\approx 3\Delta S_{\text{tot}} \left(1-\frac{t_L}{t_{\min}}\right)
\end{align}
where we assumed that $t_L\gg N_S\langle S\rangle$, which is to say
that it takes a long time to find all the interesting energy states.
Furthermore, we omitted the $\frac{t}{t_L}$ in the numerator, which is
of order unity.  This omission only makes our bound more conservative,
and enables us to solve to find that
\begin{align}
  t_{\min} &= \frac32 t_L
\end{align}
which means that we only need to run fifty percent longer after we
discover the final interesting energy state in order to have made
sufficient updates to \emph{possibly} converge to the true entropy.

\section{Results}\label{sec:results}

For the square-well fluid, our simulations treat systems with a
well-width of $\lambda = 1.3$ and $\lambda = 1.5$ and a filling fraction of
$\eta = 0.3$ and $\eta = 0.17$. We also explore various translation scales $\delta_0 = 0.005\sigma$ and
$0.05\sigma$. The simulations explore the
energy space of the systems at reduced temperatures of
$T_{\text{min}} = 0.\overline{3}$ and $1.0$.  All simulations lead to the minimum important
energy $E_{\min}$ and maximum entropy energy $E_{\max}$
being calculated (with the exception of the WL methods where both
of these parameters are needed a priori).  In the sections below, we
examine the systems parameters impact on the convergence of the methods.

We use the average entropy error vs moves as a metric to compare
simulation runtimes and overall convergence. The overall accuracy
is determined by examining the fractional error of a particular method to
a precise reference system. For each simulation, the reference system
is chosen to be the final output of the SAMC simulation with the best
choice of $t_0$.
\begin{align}
\epsilon_\text{avg} = 1 - \bigg\lvert\frac{S_\text{method}}{S_\text{ref}}\bigg\rvert
\end{align}
Simulations that take more iterations to reach the same entropy error as a
different method take longer to converge. This behavior is seen in
Fig.~\ref{fig:N50-ff0.3-avg-error}.
\jpsays{We use a SAMC $t_0 = 10^3$ with a fixed energy range $S_{\max} = 120$ and $S_{\min} = 248$ as the reference.
This is noted because this is not strictly SAMC method. We use this as a reference to increase convergence time of the
reference.}
\begin{figure}
  \includegraphics[width=\columnwidth]{figs/s000/periodic-ww1_30-ff0_30-N50-entropy-error-default.pdf}
  \caption{The average entropy error for each MC method is shown for $\eta = 0.3$ and $T_{\min} = 1/3$ with
  a fixed energy range SAMC $t_0 = 10^3$ serving as the reference.}\label{fig:N50-ff0.3-avg-error}
\end{figure}
\begin{figure}
  \includegraphics[width=\columnwidth]{figs/s000/periodic-ww1_30-ff0_30-N50-entropy-error-slow.pdf}
  \caption{The average entropy error for each MC method is shown for $\eta = 0.3$ and $T_{\min} = 1/3$ with
  a fixed energy range SAMC $t_0 = 10^3$ from Fig.~\ref{fig:N50-ff0.3-avg-error}
  serving as the reference.}\label{fig:N50-ff0.3-avg-error-slow}
\end{figure}

\subsection{A periodic system with 50 atoms}

Our smaller system consists of 50 square-well atoms with a well width
of $\lambda=1.3$, in a volume corresponding to a filling fraction of
$\eta=0.3$.  For this simulation, we chose a minimum reduced
temperature of $1/3$, which corresponds to an interesting energy range
from -248 to -120.  The entropy of this system is shown in
Fig.~\ref{fig:entropy-cartoon} above, which shows that over this
energy range the entropy differs by 198.

Figures~\ref{fig:N50-ff0.3-avg-error}
and~\ref{fig:N50-ff0.3-avg-error-slow} show the average error in the entropy vs
moves for a system consisting of 50 atoms that are placed in a periodic
simple cubic unit cell with lattice constant chosen to give a filling
fraction of $\eta = 0.3$.  These particles are randomly inserted into
the system and random moves are proposed (with a translation scale
$\delta_0 = 0.05\sigma$ and $\delta_0 = 0.005\sigma$ respectively). For
the $\eta = 30\%$ and $N = 50$ system, we explore the choice of
$\delta_0$ as a parameter.

The interesting range of energies for this system is from
{\color{blue}
$S_{\max} = 120$ and $S_{\min} = 248$ for this system.  The number of
important energy states for this system is then $N_S = S_{\min} - S_{\max} = 145$.
The reduced temperature of $1/3$ is chosen in order to examine the convergence
properties of SAD in a reasonable simulation time.

%As a side note, WL-TMMC does not converge well for $\delta_0 = 0.05\sigma$ while
%it does perform well for $\delta_0 = 0.005\sigma$. The WL portion of the algorithm
%spends nearly 100x longer for the smaller translation scale ensuring that the algorithm
%converges quickly upon transitioning to TMMC.
}

Smaller translation
scales cause the given method to take additional time to explore all
energies. Ideal methods should scale linearly with the $\delta_0$, that
is, a decrease in the translation scale should result in a proportional
increase in convergence time. As can be seen from
Fig.~\ref{fig:N50-ff0.3-avg-error-slow}, SAMC methods that rapidly
converged for $\delta = 0.05\sigma$ do not proportionaly converge for a
translation scale of $\delta = 0.005\sigma$. We see that SAD handles
arbitrary translation scales and proportionaly converges based on the
translation scale that is chosen.

\begin{figure}
\includegraphics[width=\columnwidth]{figs/s000/periodic-ww1_50-ff0_17-N256-entropy-error-default.pdf}
  \caption{The average entropy error for each MC method is shown for $\eta = 0.17$ and $T_{\min} = 1$ with
  SAD serving as the reference.}\label{fig:n256}
\end{figure}
%\begin{figure}
%\includegraphics[width=\columnwidth]{figs/s000/periodic-ww1_30-ff0_30-N500-entropy-error-default.pdf}
  %\caption{The average entropy error for each MC method is shown for $\eta = 0.3$ and $T_{\min} = 1/2$ with
  %SAMC $t_0 = 10^6$ serving as the reference.}\label{fig:n500-ff0.3}
%\end{figure}
\begin{figure}
  \includegraphics[width=\columnwidth]{figs/N256-lndos-comparison}
  \caption{Use this to create description of the system.}\label{fig:n256-lndos-comparison}
\end{figure}


\subsection{A periodic system with 256 atoms}

Figure~\ref{fig:n256} shows the average entropy vs moves for a system
consisting of 256 atoms that are placed in a periodic simple cubic unit
cell with lattice constant chosen to give a filling fraction of $\eta =
0.17$.   These particles are randomly inserted into the system and
random moves are proposed (with a translation scale $\delta_0 =
0.05\sigma$).

{\color{red}
$S_{\max} = 509$ and $S_{\min} = 915$ for this system.  The number of
important energy states for this system is then $N_S = S_{\min} -
S_{\max} = 406$. The reduced temperature of $1.0$ and well-width of $\lambda = 1.5$
are chosen in order to ensure that the simulation encounters liquid vapor coexistence
and that the results are comparable with NIST.
}

For the larger system, SAMC parameter values of $t_0$ that gave rapid
convergence for the $N = 50$ system with $\delta = 0.05\sigma$ do not
converge rapidly.  Larger $t_0$ parameters are simulated for
comparison with SAD.  SAD has significantly smaller fluctuations
in the average entropy error for a given number of moves.

{\color{red}
Figure~\ref{fig:n256-lndos-comparison} shows the calculated entropy for
the $N = 256$ system. The grey dash lines indicate the $S_{\max} = 509$
point and the $S_{\min} = 915$. Only the reference method is shown.
}

\subsubsection{Discussion on convergence and update factor}

A close examination of Fig.~\ref{fig:gamma-vs-t} shows that $\gamma$
for the Wang-Landau algorithm decreases much more rapidly than
$\nicefrac{1}{\sqrt{t}}$. It can be observed  for the simulations that
were carried out that all the methods from the weight-based family
struggle to converge if the update factor decreases too rapidlly.
Fig.~\ref{fig:N50-ff0.3-avg-error-slow} shows SAMC with inappropriate choices
of $t_0$ i.e. less than $\nicefrac{10^5}{\sqrt{t}}$ failing to converge
in a reasonable amount of time. Thus, the update factor $\gamma$, shown
as a function of simulation moves in Fig.~\ref{fig:gamma-vs-t}, proves
useful in determining which methods will converge in a reasonable
amount of time. We compare each method to a reference SAMC
simulation for an ideal choice of $t_0$.  This gives an unbiased
comparison with our developed method SAD. The dynamic version of SAMC
which we call SAD performs as well as SAMC (assuming the user can
correctly identify an appropriate choice of $t_0$ for SAMC).  SAD
outperforms WL and 1/t-WL? for the same given number of moves. The
absence of user defined parameters makes SAD an exciting alternative to
methods where user experience or successive implementation iteration
are needed to achieve reasonable results.

\section{Conclusions}

We have introduced a new algorithm SAD (Stochastic Approximation with a
Dynamic $\gamma$) that effectively samples the entire energy space for
a variety of system sizes.  Also, SAD proves effective in comparison
with other Monte-Carlo methods at converging to the correct density of
states.  The ease of implementation and the absence of user-defined
parameters makes SAD an ideal algorithm. SAD converges as quickly as
SAMC (in the case of an ideally chosen $t_0$ for our simulations. SAD
doesn't suffer from the weakness of SAMC, i.e. the user choosing
parameters that could lead to the simulation not converging in a
reasonable amount of time.
%SAD also converges more quickly than Wl,
%TMMC, and WL-TMMC.

SAD decreases $\gamma$ in a controlled way that prevents the algorithm
from taking too long to converge (as in the case of SAMC with a poor choice
of $t_0$) or failing to converge such as is the case with WL for complex
systems. A major advantage is that the user does not need to determine a
priori how quickly the update factor $\gamma$ should be decreased as the
method SAD dynamically determines this.

We note that SAD should be tested on additional systems, and the
convergence of the method should be examined.  Also, a rigorous
mathematical justification for our choice of the update factor is
necessary to ensure the most optimal convergence of the algorithm.

\section{Acknowledgement}

%We gratefully acknowledge D.W. Siderius and
%J.R. Errington for helpful communications regarding the implementation
%of WL-TMMC.

% \jpsays{Everything below this is TMI1 and GC-TMMC}

%\subsection{GC-TMMC Algorithm}
%Grand Canonical Transition Matrix Monte-Carlo (GC-TMMC) allows the energy and
%particle number of the system to fluctuate while holding the chemical potential,
%volume, and temperature constant~\cite{chen2001aggregation, chen2002simulating,
%errington2003direct, fenwick2006accurate, fenwick2008direct, errington2005direct}.
%The algorithm boasts a lower statistical noise than conventional GCMC due to its
%incorporation of a transition matrix to estimate ensemble averages~\cite{siderius2013use,
%paluch2008comparing, grzelak2008computation}.  The steps for the algorithm are
%outlined below:

%\subsubsection{Define particle insertion/deletion}
%In the system of consideration, the number of particles $\mathcal{N}$ can change
%by an amount $\delta$.  It is assumed that in the system either no particles can be
%inserted or deleted, a single insertion takes place, or a single deletion takes place.
%This yields a condition $\delta={-1,0,+1}$ for particle insertion.

%\subsubsection{Define an acceptance probability}
%Now it is necessary to define criteria for determining whether a particle insertion/deletion
%is allowed.  This criteria is called the acceptance probability and is denoted as
%\begin{align}
  %p_{a} = \min\bigg[1,\frac{\alpha_{new\rightarrow old}}
  %{\alpha_{old \rightarrow new}}\frac{\pi_{new}}{\pi_{old}}\bigg]
%\end{align}
%where $\alpha_{new\rightarrow old}$ is the probability of generating an old system
%configuration from the new.  For conventional Monte-Carlo moves $\alpha_{old \rightarrow new}
%=\alpha_{new\rightarrow old}$ although for advanced Monte-Carlo moves this would not
%be the case~\cite{siepmann1990method}.  The probabilies of actually observing the
%system in the old state is given by
%\begin{align}
  %\pi_{old} = \frac{1}{\Xi}\frac{V^{N_{old}}}{\Lambda^{3N_{old}}N_{old}!}
  %e^{-\beta(\epsilon_{old}-\mu N_{old})}
%\end{align}
%where $\Xi$ is the grand canonical partition function and $\Lambda$ is the De Broglie
%wavelength.

%\subsubsection{Define a Collection Matrix}
%In order to calculate an overall transition probability $\mathcal{P}_{N,\delta}$, we
%must first define how the system procession is to be recorded.  A Collection Matrix
%can be defined, such that for any one move, two elements are updated.
%\begin{align}
  %{C}_{N,\delta} = {C}_{N,\delta} + p_{a}\\
  %{C}_{N,0} = {C}_{N,0} +(1 - p_{a})
%\end{align}
%If $\delta=0$, that is, the number of particles has not been changed, then only
%$\mathcal{C}_{N,0}$ is incremented by unity.  The overal transition probability can
%now be defined as
%\begin{align}
  %\mathcal{P}_{N,\delta} = \frac{{C}_{N,\delta}}
  %{\sum_{j=-1}^{+1} {C}_{N,j}}
%\end{align}

%\subsubsection{Define the Particle Number Probability Distribution}
%The Particle Number Probability Distribution (PNPD) $\Pi(N;\mu,V,T)$ can be found
%by enforcing detailed balance in the system.
%\begin{align}
  %\ln(\Pi_{N+1}) = \ln(\Pi_{N}) + \ln\bigg(\frac{\mathcal{P}_{N\rightarrow N+1}}
  %{\mathcal{P}_{N+1\rightarrow N}}\bigg)
%\end{align}
%This equation will hold as long as N-space can be sampled sufficiently.  In an
%implemented algorithm $N$, $N_{min}$, and $N_{max}$ are specified for macrostate domain
%sampling.

%\subsubsection{Define a biasing function}
%The primary difference between TMMC as defined by Fitzgerald et al. and GC-TMMC as
%pioneered by JR Errington et al. is the use of a biasing function to control the acceptance
%rate of trial moves~\cite{siderius2013use, fitzgerald2000monte}.  This type of
%multi-canonical sampling augments the acceptance probability in the following way
%\begin{align}
  %p_{\eta,old\rightarrow new} = \min\bigg[1,\frac{e^{\eta(N_{new})}}
  %{e^{\eta(N_{old})}}\frac{\alpha_{new\rightarrow old}}
  %{\alpha_{old \rightarrow new}}\frac{\pi_{new}}{\pi_{old}}\bigg]
%\end{align}

%Although $p_{\eta}$ is used to control the actual transitions for trial configurations
%in GC-TMMC, $p_{a}$ is still used to update the Collection Matrices.  Ideally the biasing
%function would be given by
%\begin{align}
  %\eta(N) = -\ln\Pi(N;\mu,V,T)
%\end{align}
%Since $\Pi$ is not usually known a priori, the biasing function is usually set to some
%arbitrary constant for initialization.  The goal of this biasing function is to achieve
%uniform sampling (a common feature shared by the flat histogram Monte-Carlo family).

%\subsubsection{Histogram reweighting for the PNPD}
%Once the PNPD has beeen collected for a given chemical potential $\mu_0$, histogram
%reweighting is used to determine thermodynamic properties at other chemic potentials.
%Since the canonical partition function $Z(N,V,T)$ does not depend on the chemical
%potential, we can write
%\begin{align}
%\begin{split}
  %\Pi(N;\mu,V,T) = \frac{e^{\beta\mu N}Z(N,V,T)}{\Xi(\mu,V,T)}\\
  %\ln\Pi(N;\mu,V,T) = \ln\Pi(N;\mu_0,V,T) \\
  %+ \beta N(\mu-\mu_0) + C
%\end{split}
%\end{align}
%where $C$ is a normalization constant independent of the number of particles.


\bibliography{paper}% Produces the bibliography via BibTeX.

\end{document}
