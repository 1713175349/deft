determine metric for quality of initializations
 - max error in U/Nk or C_V/nK at T \ge min_T
make iterations vs initialization quality plot


reference file instead of reference method
input reference file and Tmin

include temp of max error in error file
error vs. temperature plot for U and CV

min counts for every energy in first round of wang landau ~ exp(1/T)
use canonical weights below important energy


ratchet min_important_energy if we have found an important slope in ln_dos


make wang_landau and tmmc dump weight aray and histogram periodically

clean up optimized_ensemble
 - throw away samples and e-hist in optimized_ensemble if we find a new min_important_energy
 - find df/dE by secant line in f(E)
   - secant line with 1/sqrt(e_hist[i]) up/down in f*e_hist[i]
   - average weights if we have an energy jump

make sure we're not breaking wang_landau by not specifying a minimum energy




run [vanilla_]wang_landau for 60, 80, 100, 150, 200
 - go from 100 to 200 by 20s?

check which methods rely on the gaussian pre-initialization



run optimized_ensemble, tmmc, and robustly_optimistic for each end condition for many small N

after figuring out what to do with end conditions, run sims with large Ns and various min_Ts


change name of "canonical MC" to "infinite temperature MC" in thesis

