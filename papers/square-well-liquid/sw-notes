
use min_important_energy in min_samples, sample_error, and optimized_ensemble

determine metric for quality of initializations
 - max error in U/Nk or C_V/nK at T \ge min_T
make iterations vs initialization quality plot

four end conditions: optimistic/pessimistic min_samples and sample errors
canonical weights after initialization with these end conditions

make wang_landau and tmmc dump weight aray and histogram periodically

clean up optimized_ensemble
 - throw away samples and e-hist in optimized_ensemble if we find a new min_important_energy
 - find df/dE by secant line in f(E)
   - secant line with 1/sqrt(e_hist[i]) up/down in f*e_hist[i]
   - average weights if we have an energy jump

revert how robustly_optimistic changes the weight array
  change how robustly_optimistic works (two free parameters, well chosen)

make sure we're not breaking wang_landau by not specifying a minimum energy




run [vanilla_]wang_landau for 60, 80, 100, 150, 200
 - go from 100 to 200 by 20s?

check which methods rely on the gaussian pre-initialization



run optimized_ensemble, tmmc, and robustly_optimistic for each end condition for many small N

after figuring out what to do with end conditions, run sims with large Ns and various min_Ts


change name of "canonical MC" to "infinite temperature MC" in thesis

